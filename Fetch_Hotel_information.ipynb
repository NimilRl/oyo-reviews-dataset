{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20893d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import pandas as pd\n",
    "import time\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2305b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "def convert_to_oyo_ids(directory):\n",
    "    \"\"\"\n",
    "    Converts CSV file names in a directory to OYO IDs.\n",
    "\n",
    "    Args:\n",
    "        directory (str): The directory path containing the CSV files.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: A DataFrame containing the OYO IDs.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Get the list of folders in the directory\n",
    "        folders = [f for f in os.listdir(directory) if os.path.isdir(os.path.join(directory, f))]\n",
    "\n",
    "        oyo_ids = []  # List to store the OYO IDs\n",
    "\n",
    "        # Iterate over each folder\n",
    "        for folder in folders:\n",
    "            folder_path = os.path.join(directory, folder)\n",
    "            csv_files = [f for f in os.listdir(folder_path) if f.endswith('.csv')]\n",
    "\n",
    "            # Iterate over each CSV file in the folder\n",
    "            for csv_file in csv_files:\n",
    "                file_name = os.path.splitext(csv_file)[0]  # Extract the file name without extension\n",
    "                oyo_id = \"https://www.oyorooms.com/{}\".format(file_name)\n",
    "                oyo_ids.append(oyo_id)\n",
    "\n",
    "        # Create a DataFrame with OYO IDs\n",
    "        result_df = pd.DataFrame({'OYO ID': oyo_ids})\n",
    "\n",
    "        return result_df\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"An error occurred while converting CSV file names to OYO IDs: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# Example usage\n",
    "directory_path = './oyo_reviews_city_wise_csv'\n",
    "result_df = convert_to_oyo_ids(directory_path)\n",
    "if result_df is not None:\n",
    "    logging.info(\"Conversion completed successfully.\")\n",
    "    print(result_df)\n",
    "else:\n",
    "    logging.warning(\"Conversion failed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ffcfb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "def scrape_oyo_hotel_data(urls):\n",
    "    \"\"\"\n",
    "    Scrapes OYO hotel data from a list of URLs.\n",
    "\n",
    "    Args:\n",
    "        urls (list): A list of URLs to scrape.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: A DataFrame containing the scraped hotel data.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        data = []  # List to store the scraped data\n",
    "\n",
    "        for i, url in enumerate(urls):\n",
    "            # Set the user agent for the request headers\n",
    "            headers = {\n",
    "                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'\n",
    "            }\n",
    "\n",
    "            # Send a GET request to the URL with the headers\n",
    "            response = requests.get(url, headers=headers)\n",
    "\n",
    "            # Check if the request was successful\n",
    "            if response.status_code == 200:\n",
    "                # Parse the HTML content using BeautifulSoup\n",
    "                soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "                \n",
    "                # Extract the hotel name\n",
    "                hotel_name = soup.find('h1', {'class': 'c-1wj1luj'}).text.strip()\n",
    "\n",
    "                # Check if the hotel is new\n",
    "                is_new_element = soup.find('div', {'class': 'c-15duxhm'})\n",
    "                is_new = 1 if is_new_element and is_new_element.text.strip() == 'NEW' else 0\n",
    "\n",
    "                # Extract the total rating\n",
    "                total_rating_element = soup.find('div', {'class': 'c-1qcdse5'})\n",
    "                total_rating = total_rating_element.text.strip() if total_rating_element else None\n",
    "\n",
    "                # Extract the price details\n",
    "                price_element = soup.find('span', {'class': 'listingPrice__finalPrice listingPrice__finalPrice--black'})\n",
    "                price = price_element.text.strip() if price_element else None\n",
    "\n",
    "                orignal_price_element = soup.find('span', {'class': 'listingPrice__slashedPrice d-body-lg'})\n",
    "                orignal_price = orignal_price_element.text.strip() if orignal_price_element else None\n",
    "\n",
    "                discount_element = soup.find('span', {'class': 'listingPrice__percentage'})\n",
    "                discount = discount_element.text.strip() if discount_element else None\n",
    "\n",
    "                # Append the scraped data to the list\n",
    "                data.append({\n",
    "                    'Hotel ID': url,\n",
    "                    'Hotel Name': hotel_name,\n",
    "                    'Is New': is_new,\n",
    "                    'Total Rating': total_rating,\n",
    "                    'Price': price,\n",
    "                    'Original Price': orignal_price,\n",
    "                    'Discount': discount\n",
    "                })\n",
    "                logging.info(f\"Scraped data for URL: {url}\")\n",
    "\n",
    "                # Create a DataFrame from the scraped data\n",
    "                df = pd.DataFrame([data[-1]])  # Only the last scraped data\n",
    "\n",
    "                # Save the DataFrame to the CSV file\n",
    "                if os.path.exists('oyo_hotel_data.csv'):\n",
    "                    df.to_csv('oyo_hotel_data.csv', mode='a', header=False, index=False)\n",
    "                else:\n",
    "                    df.to_csv('oyo_hotel_data.csv', index=False)\n",
    "\n",
    "            else:\n",
    "                logging.warning(f\"Failed to fetch the data for URL: {url}\")\n",
    "\n",
    "            # Check if it's time for a break\n",
    "            if (i + 1) % 500 == 0:\n",
    "                logging.info(\"Taking a 3-second break...\")\n",
    "                time.sleep(3)\n",
    "\n",
    "        # Create a DataFrame from the scraped data\n",
    "        df = pd.DataFrame(data)\n",
    "\n",
    "        # Check if the CSV file already exists\n",
    "        if os.path.exists('oyo_hotel_data.csv'):\n",
    "            # Read the existing CSV file\n",
    "            existing_df = pd.read_csv('oyo_hotel_data.csv')\n",
    "\n",
    "            # Append the new data to the existing DataFrame\n",
    "            df = pd.concat([existing_df, df], ignore_index=True)\n",
    "\n",
    "        # Save the DataFrame to the CSV file\n",
    "        df.to_csv('oyo_hotel_data.csv', index=False)\n",
    "\n",
    "        return df\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"An error occurred while scraping OYO hotel data: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# Example usage\n",
    "data = scrape_oyo_hotel_data(result_df['OYO ID'])\n",
    "if data is not None:\n",
    "    logging.info(\"Scraping completed successfully.\")\n",
    "    print(data)\n",
    "else:\n",
    "    logging.warning(\"Scraping failed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d954127e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
